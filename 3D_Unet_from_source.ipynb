{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardHarwood/3D_Unet_Plant_Roots/blob/main/3D_Unet_from_source.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that 3D_Unet uses H5 Data to convert 3DTIFF (most likely format ) you need to run the following:\n",
        "\n",
        "\n",
        "```\n",
        "from skimage import io\n",
        "import h5py\n",
        "\n",
        "img=skimage.io.imread(\"path to raw tif\")\n",
        "mask=skimage.io.imread(\"path to mask tif\")\n",
        "\n",
        "hf = h5py.File(\"path to new .h5 file\", 'w')\n",
        "hf.create_dataset('raw', data=img)\n",
        "hf.create_dataset('label', data=mask)\n",
        "hf.close()\n",
        "```\n",
        "\n",
        "Note that \"raw\" and \"label\" correspond to the config files used to train the model and segment data"
      ],
      "metadata": {
        "id": "ApkbnRm79loO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zxLye8HeM7h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step one load packages"
      ],
      "metadata": {
        "id": "Rcnvdp6OM-p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!pip install open3d\n",
        "!pip install vedo\n",
        "import os\n",
        "!git clone https://github.com/wolny/pytorch-3dunet.git\n",
        "%cd pytorch-3dunet\n",
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s2dmdI6H9SJN",
        "outputId": "69ab80dc-e513-4cc0-91e0-b6a2368b9e7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.18.1)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.4)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from open3d) (1.7)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.5)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (10.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.5)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (71.0.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.20.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Requirement already satisfied: vedo in /usr/local/lib/python3.10/dist-packages (2024.5.2)\n",
            "Requirement already satisfied: vtk in /usr/local/lib/python3.10/dist-packages (from vedo) (9.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vedo) (1.26.4)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.10/dist-packages (from vedo) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from vedo) (4.12.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vtk->vedo) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk->vedo) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk->vedo) (1.16.0)\n",
            "fatal: destination path 'pytorch-3dunet' already exists and is not an empty directory.\n",
            "/content/pytorch-3dunet\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing pytorch3dunet.egg-info/PKG-INFO\n",
            "writing dependency_links to pytorch3dunet.egg-info/dependency_links.txt\n",
            "writing entry points to pytorch3dunet.egg-info/entry_points.txt\n",
            "writing top-level names to pytorch3dunet.egg-info/top_level.txt\n",
            "reading manifest file 'pytorch3dunet.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'pytorch3dunet.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying pytorch3dunet/__init__.py -> build/lib/pytorch3dunet\n",
            "copying pytorch3dunet/__version__.py -> build/lib/pytorch3dunet\n",
            "copying pytorch3dunet/predict.py -> build/lib/pytorch3dunet\n",
            "copying pytorch3dunet/train.py -> build/lib/pytorch3dunet\n",
            "copying pytorch3dunet/datasets/__init__.py -> build/lib/pytorch3dunet/datasets\n",
            "copying pytorch3dunet/datasets/utils.py -> build/lib/pytorch3dunet/datasets\n",
            "copying pytorch3dunet/datasets/hdf5.py -> build/lib/pytorch3dunet/datasets\n",
            "copying pytorch3dunet/datasets/dsb.py -> build/lib/pytorch3dunet/datasets\n",
            "copying pytorch3dunet/unet3d/metrics.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/__init__.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/utils.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/predictor.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/trainer.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/se.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/buildingblocks.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/losses.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/config.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/seg_metrics.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/unet3d/model.py -> build/lib/pytorch3dunet/unet3d\n",
            "copying pytorch3dunet/augment/__init__.py -> build/lib/pytorch3dunet/augment\n",
            "copying pytorch3dunet/augment/transforms.py -> build/lib/pytorch3dunet/augment\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pytorch3dunet\n",
            "creating build/bdist.linux-x86_64/egg/pytorch3dunet/datasets\n",
            "copying build/lib/pytorch3dunet/datasets/__init__.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/datasets\n",
            "copying build/lib/pytorch3dunet/datasets/utils.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/datasets\n",
            "copying build/lib/pytorch3dunet/datasets/hdf5.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/datasets\n",
            "copying build/lib/pytorch3dunet/datasets/dsb.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/datasets\n",
            "copying build/lib/pytorch3dunet/__init__.py -> build/bdist.linux-x86_64/egg/pytorch3dunet\n",
            "creating build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/metrics.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/__init__.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/utils.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/predictor.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/trainer.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/se.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/buildingblocks.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/losses.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/config.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/seg_metrics.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/unet3d/model.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d\n",
            "copying build/lib/pytorch3dunet/__version__.py -> build/bdist.linux-x86_64/egg/pytorch3dunet\n",
            "copying build/lib/pytorch3dunet/predict.py -> build/bdist.linux-x86_64/egg/pytorch3dunet\n",
            "creating build/bdist.linux-x86_64/egg/pytorch3dunet/augment\n",
            "copying build/lib/pytorch3dunet/augment/__init__.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/augment\n",
            "copying build/lib/pytorch3dunet/augment/transforms.py -> build/bdist.linux-x86_64/egg/pytorch3dunet/augment\n",
            "copying build/lib/pytorch3dunet/train.py -> build/bdist.linux-x86_64/egg/pytorch3dunet\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/datasets/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/datasets/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/datasets/hdf5.py to hdf5.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/datasets/dsb.py to dsb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/metrics.py to metrics.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/predictor.py to predictor.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/trainer.py to trainer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/se.py to se.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/buildingblocks.py to buildingblocks.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/losses.py to losses.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/config.py to config.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/seg_metrics.py to seg_metrics.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/unet3d/model.py to model.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/__version__.py to __version__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/predict.py to predict.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/augment/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/augment/transforms.py to transforms.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pytorch3dunet/train.py to train.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytorch3dunet.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytorch3dunet.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytorch3dunet.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytorch3dunet.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pytorch3dunet.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/pytorch3dunet-1.8.7-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pytorch3dunet-1.8.7-py3.10.egg\n",
            "Removing /usr/local/lib/python3.10/dist-packages/pytorch3dunet-1.8.7-py3.10.egg\n",
            "Copying pytorch3dunet-1.8.7-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding pytorch3dunet 1.8.7 to easy-install.pth file\n",
            "Installing predict3dunet script to /usr/local/bin\n",
            "Installing train3dunet script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/pytorch3dunet-1.8.7-py3.10.egg\n",
            "Processing dependencies for pytorch3dunet==1.8.7\n",
            "Finished processing dependencies for pytorch3dunet==1.8.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that a gpu has been given, if response to below chunk is True it means training will be don on GPU, depending on the memory of your GPU you will need to change patch_size, stride_size and batch_size below. Essentially controlling the size of information that is fed into the model for a given run.\n",
        "\n"
      ],
      "metadata": {
        "id": "cRzdT70eNhlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svpPiYwPdBbs",
        "outputId": "d98417eb-9287-4c8e-ee3d-e6d6f16f7b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to mount out google drive, a pop up window will appear and you just need to enter your details"
      ],
      "metadata": {
        "id": "6Fs-0YbYN6-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ezVvAoXa5F",
        "outputId": "0de97fa9-ba29-4d4c-de42-33feda0aae03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create a suite of folders, these should all be automated for this example (which pulls data from the cloud to train). If using your own data you could keep this folder structure and just drag in your own training data into the train, qc and test folders."
      ],
      "metadata": {
        "id": "QvmGWFP_OBkD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yMgLVjjKXcBF"
      },
      "outputs": [],
      "source": [
        "#need to set appropriate  home folder\n",
        "import os.path\n",
        "from os import path\n",
        "if path.exists('/content/drive/MyDrive/3D_UNET/') == False:\n",
        "  os.mkdir('/content/drive/MyDrive/3D_UNET/')\n",
        "home_folder = \"/content/drive/MyDrive/3D_UNET/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cse0dljYYgrG"
      },
      "outputs": [],
      "source": [
        "#Create Config Folder\n",
        "if path.exists(home_folder+'config_files') == False:\n",
        "  os.mkdir(home_folder+'config_files')\n",
        "config_folder = home_folder+'config_files/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EvjePWpOYgut"
      },
      "outputs": [],
      "source": [
        "#Create Checkpoint Folder\n",
        "if path.exists(home_folder+'checkpoint_dir') == False:\n",
        "  os.mkdir(home_folder+'checkpoint_dir')\n",
        "checkpoint_dir = home_folder+'checkpoint_dir/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Training_data Folder\n",
        "\n",
        "if path.exists(home_folder+'training_data') == False:\n",
        "  os.mkdir(home_folder+'training_data')\n",
        "\n",
        "if path.exists(home_folder+'training_data/train/') == False:\n",
        "  os.mkdir(home_folder+'training_data/train/')\n",
        "\n",
        "if path.exists(home_folder+'training_data/qc/') == False:\n",
        "  os.mkdir(home_folder+'training_data/qc/')\n",
        "\n",
        "if path.exists(home_folder+'training_data/test/') == False:\n",
        "  os.mkdir(home_folder+'training_data/test/')\n",
        "\n"
      ],
      "metadata": {
        "id": "UDZbscX-884n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download example training data**\n",
        "\n",
        "Here we pull a small amount of data from zenodo that was used in the paper. It consists of 7 small crops from an imaging session at the microCT beamline at ANSTO. Of the seven images 1 is put aside to “test” 4 images for “train” and 2 images for “qc”.\n"
      ],
      "metadata": {
        "id": "7nyf5heCGpyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IoARMJUrt1JZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "04488f94-06ad-4ddb-b783-4f485c446e5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/3D_UNET/training_data/qc/img_104 (1).h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import wget\n",
        "#wget.download(\"https://zenodo.org/records/4766931/files/\"+\"E camaldulensis - Cropped.tif\"+\"?download=1\", out='/content/drive/MyDrive/3D_UNET/download_data/euc.tif')\n",
        "#Test Data\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__073_corn_pcv_ww_R5_wb_1x_stitch_6.tif_003.h5\"+\"?download=1\", out=home_folder+'training_data/test/img_76.h5')\n",
        "#Train Data\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__074_wheat_pcv_6days_R1_wb_1x_stitch.tif_022.h5\"+\"?download=1\", out=home_folder+'training_data/train/img_74.h5')\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__078_corn_pvc_2days_R3_wb_1x_stitch.tif_002.h5\"+\"?download=1\", out=home_folder+'training_data/train/img_78.h5')\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__079_corn_pvc_ww_R1_wb_1x_stitch.tif_002.h5\"+\"?download=1\", out=home_folder+'training_data/train/img_79.h5')\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__095_corn_pvc_4days_R1_wb_1x_stitch.tif_031.h5\"+\"?download=1\", out=home_folder+'training_data/train/img_95.h5')\n",
        "#QC Data\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__103_wheat_pvc_4days_R3_wb_1x_stitch.tif_011.h5\"+\"?download=1\", out=home_folder+'training_data/qc/img_103.h5')\n",
        "wget.download(\"https://zenodo.org/records/13932420/files/\"+\"recon_sub__104_wheat_pvc_ww_R5_wb_1x_stitch.tif_002.h5\"+\"?download=1\", out=home_folder+'training_data/qc/img_104.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMShYgAreOrE"
      },
      "source": [
        "**Define Model Settings**\n",
        "\n",
        "Realistically, for binary 3D segmentation all that needs to be changed here is batch_size, patch_shape and stride_shape, if you get a larger GPU these can increased. If you are using this beyond plant roots it can be valuable playing around with how much Z you capture, having a larger X Y patch and a smaller Z can improve performance if your target object in the Z isn’t too eradicate. For roots we keep a large Z patch because we want to capture the lateral roots.\n",
        "In general the more epochs the better, the model will stop after not improving after a certain amount of validation runs (you can tweak “patience” to control that\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YOz_DaM7Ygxl"
      },
      "outputs": [],
      "source": [
        "model_name = \"UNet3D\"\n",
        "in_channels = 1\n",
        "out_channels= 1\n",
        "layer_order = \"gcr\"\n",
        "f_maps = [32,\n",
        "          64,\n",
        "          128,\n",
        "          256]\n",
        "num_groups = 8\n",
        "final_sigmoid = True\n",
        "is_segmentation = True\n",
        "resume = None\n",
        "pre_trained = None\n",
        "validate_after_iters = 500\n",
        "log_after_iters = 500\n",
        "max_num_epochs = 10  ##Low for testing\n",
        "max_num_iterations = 1800000\n",
        "eval_score_higher_is_better = True\n",
        "loss_name= 'BCEWithLogitsLoss'\n",
        "learning_rate= 0.0002\n",
        "weight_decay= 0.00001\n",
        "eval_name= \"MeanIoU\"\n",
        "lr_name= \"ReduceLROnPlateau\"\n",
        "mode= 'max'\n",
        "factor = 0.2\n",
        "patience = 30\n",
        "dataset= \"StandardHDF5Dataset\"\n",
        "batch_size= 3  #important for gpu memory\n",
        "num_workers= 2\n",
        "raw_internal_path= \"raw\"\n",
        "label_internal_path= \"label\"\n",
        "weight_internal_path= None\n",
        "################3\n",
        "file_paths_train= home_folder+'training_data/train/'\n",
        "######################\n",
        "slice_builder_name= \"SliceBuilder\"\n",
        "slice_builder_name_predict = \"SliceBuilder\"\n",
        "patch_shape= [40, 170, 170]  #Change depending on GPU memory\n",
        "stride_shape= [20, 40, 40]   #Change depending on GPU memory\n",
        "halo_shape= [16, 32, 32]\n",
        "threshold = 0.01\n",
        "slack_acceptance = 0.01\n",
        "name_transformer= \"Standardize\"\n",
        "name_transformer_label= \"BlobsToMask\"\n",
        "append_label= False\n",
        "boundary= False\n",
        "ToTensor_name = \"ToTensor\"\n",
        "expand_dims_false= False\n",
        "expand_dims_true= True\n",
        "################\n",
        "file_paths_val= home_folder+'training_data/qc/'\n",
        "#####################\n",
        "predictor_name='StandardPredictor'\n",
        "#################################\n",
        "file_paths_test= home_folder+'training_data/test/'\n",
        "#############################\n",
        "model_path=checkpoint_dir+\"best_checkpoint.pytorch\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdgWzdffebOU"
      },
      "source": [
        "**Create the \"train.yaml\" file**\n",
        "\n",
        "To run the model we create a .yaml file, essentially a structured text file. This means that every setting we used is logged and saved in the google drive (or hard drive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hzeBYx8hYg0F"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#https://stackoverflow.com/questions/12470665/how-can-i-write-data-in-yaml-format-in-a-file\n",
        "#https://stackoverflow.com/questions/59034564/yaml-dump-seeming-to-add-two-dashes-to-2nd-row-under-first-key\n",
        "\n",
        "\n",
        "import yaml\n",
        "train_intrem_config = {'model':{'name':model_name,\n",
        "                                'in_channels':in_channels,\n",
        "                                'out_channels':out_channels,\n",
        "                                'layer_order':layer_order,\n",
        "                                'f_maps':f_maps,\n",
        "                                'num_groups':num_groups,\n",
        "                                'final_sigmoid':final_sigmoid,\n",
        "                                'is_segmentation':is_segmentation},\n",
        "                       'trainer': {'checkpoint_dir':checkpoint_dir,\n",
        "                                   'resume':resume,\n",
        "                                   'pre_trained':pre_trained,\n",
        "                                   'validate_after_iters':validate_after_iters,\n",
        "                                   'log_after_iters':log_after_iters,\n",
        "                                   'max_num_epochs':max_num_epochs,\n",
        "                                   'max_num_iterations':max_num_iterations,\n",
        "                                   'eval_score_higher_is_better':eval_score_higher_is_better},\n",
        "                       'loss':{'name':loss_name},\n",
        "                       'optimizer':{'learning_rate':learning_rate,\n",
        "                                    'weight_decay':weight_decay},\n",
        "                       'eval_metric':{'name':eval_name},\n",
        "                       'lr_scheduler':{'name':lr_name,\n",
        "                                       'mode':mode,\n",
        "                                       'factor':factor,\n",
        "                                       'patience':patience},\n",
        "                       'loaders':{'dataset':dataset,\n",
        "                                       'batch_size':batch_size,\n",
        "                                       'num_workers':num_workers,\n",
        "                                       'raw_internal_path':raw_internal_path,\n",
        "                                       'label_internal_path':label_internal_path,\n",
        "                                       'weight_internal_path':weight_internal_path,\n",
        "                       'train':{'file_paths':[file_paths_train],\"slice_builder\":{'name':slice_builder_name,\n",
        "                                                                               'patch_shape':patch_shape,\n",
        "                                                                               'stride_shape':stride_shape,\n",
        "                                                                               'threshold':threshold,\n",
        "                                                                               'slack_acceptance':slack_acceptance},\n",
        "                       'transformer': {\"raw\": [{\"name\":name_transformer},\n",
        "                                               {\"name\":ToTensor_name,\n",
        "                                                \"expand_dims\":expand_dims_true}],\n",
        "                                       \"label\": [{\"name\":name_transformer_label,\n",
        "                                                \"append_label\":append_label},\n",
        "                                               {\"name\":ToTensor_name,\n",
        "                                                \"expand_dims\":expand_dims_false}]}},\n",
        "                       'val':{\"file_paths\":[file_paths_val],\"slice_builder\":{'name':slice_builder_name,\n",
        "                                                                               'patch_shape':patch_shape,\n",
        "                                                                               'stride_shape':patch_shape,\n",
        "                                                                               'threshold':threshold,\n",
        "                                                                               'slack_acceptance':slack_acceptance},\n",
        "                       'transformer': {\"raw\": [{\"name\":name_transformer},\n",
        "                                               {\"name\":ToTensor_name,\n",
        "                                                \"expand_dims\":expand_dims_true}],\n",
        "                                       \"label\": [{\"name\":name_transformer_label,\n",
        "                                                  \"append_label\":append_label},\n",
        "                                               {\"name\":ToTensor_name,\n",
        "                                                \"expand_dims\":expand_dims_false}]}}}}\n",
        "\n",
        "with open(config_folder+'model_train.yaml', 'w') as yaml_file:\n",
        "    yaml.dump(train_intrem_config, yaml_file, default_flow_style=False, sort_keys=False)\n",
        "\n",
        " #print(yaml.dump(train_intrem_config, default_flow_style=False, sort_keys=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ2PrLychl4N"
      },
      "source": [
        "**Start Training**\n",
        "\n",
        "To start training we run \"train3dunet –config \"path to train yaml\" after an exclamation mark.  \n",
        "\n",
        "the exclamation mark (!) allows users to run shell commands from inside a Jupyter Notebook code cell).\n",
        "\n",
        "So to train we run\n",
        "\n",
        "`!train3dunet --config /content/drive/MyDrive/3D_UNET/config_files/model_train.yaml`\n",
        "\n",
        "**Note:** that this really depends on using the folder structure defined above.\n",
        "\n",
        "**Note:** that if you don’t want to train (for example you have already trained a model and you want to segment data put a “#” in front of the text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UmqhZffZY6Qe"
      },
      "outputs": [],
      "source": [
        "#!train3dunet --config /content/drive/MyDrive/3D_UNET/config_files/model_train.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v7l9uAyQXyCW"
      },
      "outputs": [],
      "source": [
        "test_config_yaml ={\n",
        "    \"model_path\": model_path,\n",
        "    \"model\": {\n",
        "        \"name\": model_name,\n",
        "        \"in_channels\": in_channels,\n",
        "        \"out_channels\": out_channels,\n",
        "        \"layer_order\": layer_order,\n",
        "        \"f_maps\": f_maps,\n",
        "        \"num_groups\": num_groups,\n",
        "        \"final_sigmoid\": final_sigmoid,\n",
        "        \"is_segmentation\": is_segmentation\n",
        "    },\n",
        "    \"predictor\": {\n",
        "        \"name\": predictor_name\n",
        "    },\n",
        "    \"loaders\": {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"raw_internal_path\": raw_internal_path,\n",
        "        \"num_workers\": num_workers,\n",
        "        \"test\": {\n",
        "            \"file_paths\": [\n",
        "                file_paths_test\n",
        "            ],\n",
        "            \"slice_builder\": {\n",
        "                \"name\": slice_builder_name_predict,\n",
        "                \"patch_shape\": patch_shape,\n",
        "                \"stride_shape\": patch_shape,\n",
        "                \"halo_shape\": halo_shape\n",
        "            },\n",
        "            \"transformer\": {\n",
        "                \"raw\": [\n",
        "                    {\n",
        "                        \"name\": name_transformer\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": ToTensor_name,\n",
        "                        \"expand_dims\": expand_dims_true\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(config_folder+'predict.yaml', 'w') as yaml_file:\n",
        "    yaml.dump(test_config_yaml, yaml_file, default_flow_style=False, sort_keys=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6qTwvfj-Xc6l"
      },
      "outputs": [],
      "source": [
        "#print(yaml.dump(test_config_yaml, default_flow_style=False, sort_keys=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start Predicting**\n",
        "\n",
        "Currently this assumes we are using the model we trained above, if using a different model define “model_path” acconringly and if need be tweak any details of the test_config.yaml\n",
        "\n",
        "The test_config.yaml will run the 3D-Unet model on every image in a folder, it will export out an image of confidence values for each voxel (0, the model thinks the voxel isn’t a root, higher values indicate more confidence the voxel is a root)\n",
        "\n",
        "Running the sgemenation is the same as training the model\n",
        "\n",
        "`!predict3dunet --config /content/drive/MyDrive/3D_UNET/config_files/predict.yaml`\n",
        "\n",
        "The segmented files will have the same name but .prediction gets added to the end of the file name.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x0fzX9JCRLci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YLP8lMgeXdqu"
      },
      "outputs": [],
      "source": [
        "#!predict3dunet --config /content/drive/MyDrive/3D_UNET/config_files/predict.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dealing with the output**\n",
        "**Dealing with the output**\n",
        "Now we have a folder with segmented image(s), in h5 format that we need to sort out.\n",
        "\n",
        "To start we create a folder “processed” this is where our formatted output will go.\n",
        "\n",
        "Below is one example of dealing with the direct model output. It involves using a threshold to create a binary image of the root (from the confidence values 3D image) then it removes small objects to omit voxels that shouldn’t be counted (e.g. organic matter). From this file a 3D mesh is created, and it can be viewed in the last chunk but copying and pasting the. stl file location.\n",
        "\n",
        "The post processing steps will be dictated by how good your model is, how uniform your scans are, what GPU you can access (e.g. smaller patch sizes will create more issues)\n",
        "\n"
      ],
      "metadata": {
        "id": "lw0bfMdHSTyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sy6frieCWTrE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E63bn_rxXeD9",
        "outputId": "ad891bd3-7664-426c-c2bd-4c5657326c52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "raw_data_path= file_paths_test\n",
        "raw_file_names = [os.path.basename(x) for x in glob.glob(raw_data_path+\"*.h5\")]\n",
        "raw_file_names = [e for e in raw_file_names if \"predictions\" in e ]\n",
        "#################################\n",
        "if path.exists(home_folder+'processed/') == False:\n",
        "  os.mkdir(home_folder+'processed/')\n",
        "\n",
        "file_paths_processed= home_folder+'processed/'\n",
        "#########################\n",
        "raw_file_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNr9Phtbuny1",
        "outputId": "8eff7889-dd3f-498b-bf41-79c0c5e84f52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "UNIQUE_ID =np.unique(raw_file_names)\n",
        "len(UNIQUE_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-V0RC9xEun9Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import h5py\n",
        "import cv2\n",
        "import skimage\n",
        "from skimage.filters import threshold_otsu, threshold_yen\n",
        "from skimage.measure import label\n",
        "from skimage.morphology import remove_small_objects\n",
        "from vedo import *\n",
        "for i in UNIQUE_ID:\n",
        "    print(i)\n",
        "    hf=h5py.File(raw_data_path+i)\n",
        "    hf.keys()\n",
        "    dataset_IMGs= hf['predictions']\n",
        "    image=dataset_IMGs[:]\n",
        "    image=image[0,:,:,:]\n",
        "    #image=zoom(image, (scale_factor,scale_factor, scale_factor), order=1)\n",
        "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    thresh = threshold_yen(image)-45\n",
        "    #thresh=20\n",
        "    print (thresh)\n",
        "    binary = image > thresh\n",
        "    #binary=zoom(binary, (scale_factor,scale_factor, scale_factor), order=0)\n",
        "    root_sml=label(binary)\n",
        "    min_size_coef=2500 #trial and error really\n",
        "    root_sml_obj = remove_small_objects(root_sml, min_size=min_size_coef, connectivity=2)\n",
        "    root_sml_obj = (root_sml_obj != 0).astype(bool)\n",
        "\n",
        "    root_VOL = Volume(root_sml_obj, spacing=((1),(1),(1)))\n",
        "    root_ISO = root_VOL.isosurface(1)\n",
        "    root_ISO.write(file_paths_processed+i+\"__root.stl\")\n",
        "    skimage.io.imsave(file_paths_processed+i+\"_processed.tif\", root_sml_obj, check_contrast=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laYXrvDp_N20"
      },
      "source": [
        "Now, to sanity check lets create a 3D model of the root system we just segmented using 3D-Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "WAEf_MwV-G16",
        "outputId": "7efb894c-5def-4989-fc02-60c6131493e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m[Open3D WARNING] Unable to load file /content/drive/MyDrive/3D_UNET/processed/recon_sub__103_wheat_pvc_4days_R3_wb_1x_stitch.tif_014_predictions.h5__root.stl with ASSIMP\u001b[0;m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"22adf2ab-c10c-4168-bfb0-32803c616a78\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"22adf2ab-c10c-4168-bfb0-32803c616a78\")) {                    Plotly.newPlot(                        \"22adf2ab-c10c-4168-bfb0-32803c616a78\",                        [{\"facecolor\":[1.0,0.0,0.0],\"i\":[],\"j\":[],\"k\":[],\"opacity\":0.5,\"x\":[],\"y\":[],\"z\":[],\"type\":\"mesh3d\"}],                        {\"scene\":{\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false},\"zaxis\":{\"visible\":false}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('22adf2ab-c10c-4168-bfb0-32803c616a78');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import open3d as o3d\n",
        "import plotly.graph_objects as go\n",
        "model_to_test=\"recon_sub__103_wheat_pvc_4days_R3_wb_1x_stitch.tif_014_predictions.h5__root.stl\"\n",
        "mesh = o3d.io.read_triangle_mesh(file_paths_processed+model_to_test)\n",
        "if not mesh.has_vertex_normals(): mesh.compute_vertex_normals()\n",
        "if not mesh.has_triangle_normals(): mesh.compute_triangle_normals()\n",
        "triangles = np.asarray(mesh.triangles)\n",
        "vertices = np.asarray(mesh.vertices)\n",
        "colors = None\n",
        "\n",
        "colors = (1.0, 0.0, 0.0)\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Mesh3d(\n",
        "            x=vertices[:,0],\n",
        "            y=vertices[:,1],\n",
        "            z=vertices[:,2],\n",
        "            i=triangles[:,0],\n",
        "            j=triangles[:,1],\n",
        "            k=triangles[:,2],\n",
        "            facecolor=colors,\n",
        "            opacity=0.50)\n",
        "    ],\n",
        "    layout=dict(\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=False),\n",
        "            yaxis=dict(visible=False),\n",
        "            zaxis=dict(visible=False)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyObznhisvkpQBf+kNn1RiSz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}