{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWLAdCqRSqx7D19/88FV7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardHarwood/3D_Unet_Plant_Roots/blob/main/3D_Unet_general_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3yaDEUhWVGi"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install open3d\n",
        "!pip install vedo\n",
        "#!pip install stackview ipycanvas==0.11\n",
        "import os\n",
        "!git clone https://github.com/wolny/pytorch-3dunet.git\n",
        "%cd pytorch-3dunet\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "FI472u3oWbZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cBgZm7avWbMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#need to set appropriate  home folder\n",
        "import os.path\n",
        "from os import path\n",
        "if path.exists('/content/drive/MyDrive/3D_UNET_general_eg/') == False:\n",
        "  os.mkdir('/content/drive/MyDrive/3D_UNET_general_eg/')\n",
        "home_folder = \"/content/drive/MyDrive/3D_UNET_general_eg/\""
      ],
      "metadata": {
        "id": "BC8_Rt9yWa_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Config Folder\n",
        "if path.exists(home_folder+'config_files') == False:\n",
        "  os.mkdir(home_folder+'config_files')\n",
        "config_folder = home_folder+'config_files/'"
      ],
      "metadata": {
        "id": "JNBSbScwWaxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Checkpoint Folder\n",
        "if path.exists(home_folder+'checkpoint_dir') == False:\n",
        "  os.mkdir(home_folder+'checkpoint_dir')\n",
        "checkpoint_dir = home_folder+'checkpoint_dir/'"
      ],
      "metadata": {
        "id": "WPGCwgHhWalT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Folder to store images we want to segment\n",
        "if path.exists(home_folder+'segment_this_folder') == False:\n",
        "  os.mkdir(home_folder+'segment_this_folder')\n",
        "imgs_to_seg_dir = home_folder+'segment_this_folder/'"
      ],
      "metadata": {
        "id": "DM4aCHNcWaYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download data that the model has never seen before**\n"
      ],
      "metadata": {
        "id": "dVmeAC8kXkmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "wget.download(\"https://zenodo.org/records/13958667/files/\"+\"2-3_enhanced.tif.h5\"+\"?download=1\", out=imgs_to_seg_dir+'2-3_enhanced.tif.h5')"
      ],
      "metadata": {
        "id": "yTrsmesrX4s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the model trained from Harwood et al hand segmentations**\n"
      ],
      "metadata": {
        "id": "H5ob3W_OXsr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wget.download(\"https://zenodo.org/records/13958667/files/\"+\"3D_Unet_Root_Model.pytorch\"+\"?download=1\", out=checkpoint_dir+'3D_Unet_Root_Model.pytorch')"
      ],
      "metadata": {
        "id": "GqXv97nkX5Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Look at the data we want to segment**"
      ],
      "metadata": {
        "id": "WL82pVQ8a0-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "hf=h5py.File(imgs_to_seg_dir+'2-3_enhanced.tif.h5')\n",
        "hf.keys()\n",
        "raw_IMGs= hf['raw']\n",
        "image_raw=raw_IMGs[:]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image_raw[3], cmap=\"gray\");"
      ],
      "metadata": {
        "id": "m9F5M7Bka1f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a config file to segment the downloaded image with the downloaded model**"
      ],
      "metadata": {
        "id": "mTnH38CxX6J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"UNet3D\"\n",
        "in_channels = 1\n",
        "out_channels= 1\n",
        "layer_order = \"gcr\"\n",
        "f_maps = [32,\n",
        "          64,\n",
        "          128,\n",
        "          256]\n",
        "num_groups = 8\n",
        "final_sigmoid = True\n",
        "is_segmentation = True\n",
        "batch_size= 3  #important for gpu memory\n",
        "num_workers= 2\n",
        "raw_internal_path= \"raw\"\n",
        "label_internal_path= \"label\"\n",
        "weight_internal_path= None\n",
        "######################\n",
        "slice_builder_name= \"SliceBuilder\"\n",
        "slice_builder_name_predict = \"SliceBuilder\"\n",
        "patch_shape= [40, 170, 170]  #Change depending on GPU memory\n",
        "stride_shape= [20, 40, 40]   #Change depending on GPU memory\n",
        "halo_shape= [16, 32, 32]\n",
        "threshold = 0.01\n",
        "slack_acceptance = 0.01\n",
        "name_transformer= \"Standardize\"\n",
        "name_transformer_label= \"BlobsToMask\"\n",
        "append_label= False\n",
        "boundary= False\n",
        "ToTensor_name = \"ToTensor\"\n",
        "expand_dims_false= False\n",
        "expand_dims_true= True\n",
        "#####################\n",
        "predictor_name='StandardPredictor'\n",
        "#################################\n",
        "file_paths_test= imgs_to_seg_dir\n",
        "#############################\n",
        "model_path=checkpoint_dir+'3D_Unet_Root_Model.pytorch'"
      ],
      "metadata": {
        "id": "n1xQv7nrWaG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "test_config_yaml ={\n",
        "    \"model_path\": model_path,\n",
        "    \"model\": {\n",
        "        \"name\": model_name,\n",
        "        \"in_channels\": in_channels,\n",
        "        \"out_channels\": out_channels,\n",
        "        \"layer_order\": layer_order,\n",
        "        \"f_maps\": f_maps,\n",
        "        \"num_groups\": num_groups,\n",
        "        \"final_sigmoid\": final_sigmoid,\n",
        "        \"is_segmentation\": is_segmentation\n",
        "    },\n",
        "    \"predictor\": {\n",
        "        \"name\": predictor_name\n",
        "    },\n",
        "    \"loaders\": {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"raw_internal_path\": raw_internal_path,\n",
        "        \"num_workers\": num_workers,\n",
        "        \"test\": {\n",
        "            \"file_paths\": [\n",
        "                file_paths_test\n",
        "            ],\n",
        "            \"slice_builder\": {\n",
        "                \"name\": slice_builder_name_predict,\n",
        "                \"patch_shape\": patch_shape,\n",
        "                \"stride_shape\": patch_shape,\n",
        "                \"halo_shape\": halo_shape\n",
        "            },\n",
        "            \"transformer\": {\n",
        "                \"raw\": [\n",
        "                    {\n",
        "                        \"name\": name_transformer\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": ToTensor_name,\n",
        "                        \"expand_dims\": expand_dims_true\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(config_folder+'predict.yaml', 'w') as yaml_file:\n",
        "    yaml.dump(test_config_yaml, yaml_file, default_flow_style=False, sort_keys=False)\n"
      ],
      "metadata": {
        "id": "wLwd02WDWZEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start Predicting**\n",
        "\n",
        "Currently this assumes we are using the model we trained above, if using a different model define “model_path” acconringly and if need be tweak any details of the test_config.yaml\n",
        "\n",
        "The test_config.yaml will run the 3D-Unet model on every image in a folder, it will export out an image of confidence values for each voxel (0, the model thinks the voxel isn’t a root, higher values indicate more confidence the voxel is a root)\n",
        "\n",
        "Running the sgemenation is the same as training the model\n",
        "\n",
        "`!predict3dunet --config /content/drive/MyDrive/3D_UNET/config_files/predict.yaml`\n",
        "\n",
        "The segmented files will have the same name but .prediction gets added to the end of the file name."
      ],
      "metadata": {
        "id": "YlbfJe8pcPrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!predict3dunet --config /content/drive/MyDrive/3D_UNET_general_eg/config_files/predict.yaml"
      ],
      "metadata": {
        "id": "XnxlKBIvbXxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "raw_data_path= file_paths_test\n",
        "raw_file_names = [os.path.basename(x) for x in glob.glob(imgs_to_seg_dir+\"*.h5\")]\n",
        "raw_file_names = [e for e in raw_file_names if \"predictions\" in e ]\n",
        "#################################\n",
        "if path.exists(home_folder+'processed/') == False:\n",
        "  os.mkdir(home_folder+'processed/')\n",
        "\n",
        "file_paths_processed= home_folder+'processed/'\n",
        "#########################\n",
        "raw_file_names\n"
      ],
      "metadata": {
        "id": "o7F1EqNKbYi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNIQUE_ID =np.unique(raw_file_names)\n",
        "len(UNIQUE_ID)"
      ],
      "metadata": {
        "id": "LoM4JZ9BeFxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import cv2\n",
        "import skimage\n",
        "from skimage.filters import threshold_otsu, threshold_yen\n",
        "from skimage.measure import label\n",
        "from skimage.morphology import remove_small_objects\n",
        "from vedo import *\n",
        "for i in UNIQUE_ID:\n",
        "    print(i)\n",
        "    hf=h5py.File(raw_data_path+i)\n",
        "    hf.keys()\n",
        "    dataset_IMGs= hf['predictions']\n",
        "    image=dataset_IMGs[:]\n",
        "    image=image[0,:,:,:]\n",
        "    #image=zoom(image, (scale_factor,scale_factor, scale_factor), order=1)\n",
        "    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    #thresh = threshold_yen(image)-45\n",
        "    thresh=1\n",
        "    print (thresh)\n",
        "    binary = image > thresh\n",
        "    #the below steps might be useful is your 3D output is not so great\n",
        "    #binary=zoom(binary, (scale_factor,scale_factor, scale_factor), order=0)\n",
        "    #root_sml=label(binary)\n",
        "    #min_size_coef=1500 #trial and error really\n",
        "    #root_sml_obj = remove_small_objects(root_sml, min_size=min_size_coef, connectivity=2)\n",
        "    #root_sml_obj = (root_sml_obj != 0).astype(bool)\n",
        "\n",
        "    root_VOL = Volume(binary, spacing=((1),(1),(1)))\n",
        "    root_ISO = root_VOL.isosurface(1)\n",
        "    root_ISO.write(file_paths_processed+i+\"__root.stl\")\n",
        "    skimage.io.imsave(file_paths_processed+i+\"_processed.tif\", binary, check_contrast=False)"
      ],
      "metadata": {
        "id": "ZujfPEHbbYqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=[10, 4]);\n",
        "ax[0].imshow(image_raw[20], cmap=\"gray\");\n",
        "ax[0].set_title('raw image');\n",
        "\n",
        "ax[1].imshow(image[20], vmin=0, vmax=15);\n",
        "ax[1].set_title('3D Unet Seg');"
      ],
      "metadata": {
        "id": "tA17X3c0egyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import plotly.graph_objects as go\n",
        "model_to_test=\"2-3_enhanced.tif_predictions.h5__root.stl\"\n",
        "mesh = o3d.io.read_triangle_mesh(file_paths_processed+model_to_test)\n",
        "if not mesh.has_vertex_normals(): mesh.compute_vertex_normals()\n",
        "if not mesh.has_triangle_normals(): mesh.compute_triangle_normals()\n",
        "triangles = np.asarray(mesh.triangles)\n",
        "vertices = np.asarray(mesh.vertices)\n",
        "colors = None\n",
        "\n",
        "colors = (1.0, 0.0, 0.0)\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Mesh3d(\n",
        "            x=vertices[:,0],\n",
        "            y=vertices[:,1],\n",
        "            z=vertices[:,2],\n",
        "            i=triangles[:,0],\n",
        "            j=triangles[:,1],\n",
        "            k=triangles[:,2],\n",
        "            facecolor=colors,\n",
        "            opacity=0.50)\n",
        "    ],\n",
        "    layout=dict(\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=False),\n",
        "            yaxis=dict(visible=False),\n",
        "            zaxis=dict(visible=False)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "E6kscm9cbYyt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}